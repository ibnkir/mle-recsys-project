KN, 21-Jul-2024, 6pm
Антон, привет, отправляю проект на проверку.

Прошу обратить внимание, что датасет interactions слишком большой даже для ВМ (5+ гигов),
Python падает на каждой ячейке, работать невозможно.
Я пытался его сократить разными способами. 
Например, оставил int32 у всех идентификаторов. 
Удалил треки, у которых хотя бы одна из 4-х категорий пустая,
со всеми их событиями, но датасет все равно занимает 5+ G.

В итоге, чтобы сократить interactions до разумных 1.5-2G, мне пришлось оставить только юзеров, 
прослушавших за год 1000 треков и более. Из-за этого потеряли смысл оценки на валидации. 
В общем, прошу учесть, что датасет не расчитан на выделенные ресурсы.
Поэтому предлагаю сфокусироваться на технической реализации, а не на оценках.
Либо нужно исправлять исходный датасет / добавлять мощностей в облаке (хотя похоже, что
без явных кластерных вычислений питон все равно не переварит датасет такого большого размера)